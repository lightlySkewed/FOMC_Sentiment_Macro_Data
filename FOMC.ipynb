{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo:\n",
    "\n",
    "Plot important dates against our output: https://www.policyuncertainty.com/media/US_Annotated_Series.pdf\n",
    "\n",
    "1) Bush Election\n",
    "2) 9/11\n",
    "3) Gulf War II\n",
    "4) Stimulus Debate ~2007/ 2008\n",
    "5) Lehman/ TARP ~2008/ 2009\n",
    "6) Eurozone Crisis/ US Midterm Elections ~Nov 2010\n",
    "7) Debt Ceiling Debate ~2011/2012\n",
    "8) Fiscal Cliff ~2013\n",
    "9) Govt. Shutdown ~2013/ 2014\n",
    "10) Brexit ~2016\n",
    "11) Trump Election ~Nov 2016\n",
    "12) US out of TPP ~2016/ 2017\n",
    "13) Tarrifs 2018\n",
    "\n",
    "Market Dates: https://www.timetoast.com/timelines/important-dates-in-the-history-of-the-u-s-stock-markets\n",
    "\n",
    "1) Dot Com Bubble = Mar 10, 2000\n",
    "2) NASDAQ Drop 356 Points = Apr 14, 2000\n",
    "3) Hurricane Katrina = Aug 25, 2005\n",
    "4) 2008 Market Selloff = 09/29/2008, 10/08/2008, 10/15/2008, 10/22/2008, 12/01/2008, 12/10/2008\n",
    "5) 2011 Market Selloff = 08/04/2011, 08/08/2011, 09/17/2011, 12/31/2011\n",
    "6) Derive other dates from SPX data\n",
    "\n",
    "https://fraser.stlouisfed.org/timeline/covid-19-pandemic\n",
    "\n",
    "https://fraser.stlouisfed.org/timeline/financial-crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False #for intellisense compatibility w/ Jupyter Notebook\n",
    "import pandas as pd\n",
    "import ipdb\n",
    "import copy\n",
    "from iGetByWithALittle import find_target_columns, find_new_obs_percent_chg, find_index_in_Excel_File_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Vintage GDP Data from ALFRED File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://alfred.stlouisfed.org/series/downloaddata?seid=GDPC1\n",
    "#Note: Must select 'All' in the Vintage Dates section. Data as of 1/9/2021\n",
    "dfA = pd.read_excel(io='GDPC1_2.xls', sheet_name=1) #read in first sheet of vintages\n",
    "dfB = pd.read_excel(io='GDPC1_2.xls', sheet_name=2) #read in second sheet of vintages\n",
    "dfA.set_index('observation_date', inplace=True) #set index to observation date for join\n",
    "dfB.set_index('observation_date', inplace=True) #set index to observation date for join\n",
    "df = dfA.join(dfB) #join sheets' data to single data frame\n",
    "df = df.loc['1999-01-01':] #discard data prior to 1999 as our series begins in 2000\n",
    "years_cols_list = find_target_columns(df, 6, 10, 1999) #find columns where year >= 1999\n",
    "df = df.filter(years_cols_list, axis=1) #filter df on columns list\n",
    "df = df.drop(columns=\"GDPC1_20031210\") #drop 2003 benchmark revision without last observation. this should be static though it wouldn't hurt to write a function to id 'shorter' columns as it iterates\n",
    "df['Curr GDP Pct Chg'] = find_new_obs_percent_chg(df, 4, 0) #find the percent change given new quarterly observations\n",
    "GDPC1_cols_list = find_target_columns(df, 0, 5, 'GDPC1') #find columns which contain 'GDPC1'\n",
    "GDP_actuals = df.drop(columns=GDPC1_cols_list) #remove levels data\n",
    "GDP_actuals['Prev GDP Pct Chg'] = GDP_actuals['Curr GDP Pct Chg'].shift() #lag previous periods GDP percent change\n",
    "GDP_actuals = GDP_actuals[['Prev GDP Pct Chg', 'Curr GDP Pct Chg']] #list to define column order\n",
    "GDP_actuals.index = GDP_actuals.index.to_period(\"Q\") #format index\n",
    "GDP_actuals.index.rename('Period', inplace = True) #rename index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Vintage GDP Chain-Type Price Index Data from ALFRED File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://alfred.stlouisfed.org/series/downloaddata?seid=GDPCTPI\n",
    "#NOTE: Must select 'All' in the Vintage Dates section. Data as of 1/12/2021\n",
    "dfA = pd.read_excel(io='GDPCTPI_2.xls', sheet_name=1) #read in first sheet of vintages\n",
    "dfB = pd.read_excel(io='GDPCTPI_2.xls', sheet_name=2) #read in second sheet of vintages\n",
    "dfA.set_index('observation_date', inplace=True) #set index to observation date for join\n",
    "dfB.set_index('observation_date', inplace=True) #set index to observation date for join\n",
    "df = dfA.join(dfB) #join sheets' data to single data frame\n",
    "df = df.loc['1999-01-01':] #discard data prior to 1999 as our series begins in 2000\n",
    "years_cols_list = find_target_columns(df, 8, 12, 1999) #find columns where year >= 1999\n",
    "df = df.filter(years_cols_list, axis=1) #filter df on columns list\n",
    "df = df.drop(columns=\"GDPCTPI_20031210\") #drop 2003 benchmark revision without last observation. this should be static though it wouldn't hurt to write a function to id 'shorter' columns as it iterates\n",
    "df['Curr PGDP Pct Chg'] = find_new_obs_percent_chg(df, 4, 0) #find the percent change given new quarterly observations\n",
    "GDPCTPI_cols_list = find_target_columns(df, 0, 5, 'GDPCTPI') #find columns which contain 'GDPC1'\n",
    "PGDP_actuals = df.drop(columns=GDPCTPI_cols_list) #remove levels data\n",
    "PGDP_actuals['Prev PGDP Pct Chg'] = PGDP_actuals['Curr PGDP Pct Chg'].shift() #lag previous periods GDP percent change\n",
    "PGDP_actuals = PGDP_actuals[['Prev PGDP Pct Chg', 'Curr PGDP Pct Chg']] #list to define column order\n",
    "PGDP_actuals.index = PGDP_actuals.index.to_period(\"Q\") #format index\n",
    "PGDP_actuals.index.rename('Period', inplace = True) #rename index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Vintage PCE Data from ALFRED File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://alfred.stlouisfed.org/series/downloaddata?seid=PCEPILFE\n",
    "#Note: Must select 'All' in the Vintage Dates section. Data as of 1/9/2021\n",
    "# Might want to dig a little harder here. Could be a better vintage series...\n",
    "df = pd.read_excel(io='PCEPILFE_2.xls', sheet_name=1) #read in data\n",
    "df.set_index('observation_date', inplace=True) #set index\n",
    "df = df.loc['2006-01-01':] #filter extra data\n",
    "PCE_cols_list = find_target_columns(df, 9, 13, 2006) #identify columns we want to retain\n",
    "df = df.filter(PCE_cols_list, axis=1) #retain identified columns\n",
    "df = df.resample('Q').sum(min_count=3)/3 #resample monthly data to quarterly to match Philly convention\n",
    "df['Curr PCE Pct Chg'] = find_new_obs_percent_chg(df, 1, 1) #find vintage percent changes to match Philly convention \n",
    "PCEPI_cols_list = find_target_columns(df, 0, 5, 'PCEPI') #identify columns to remove\n",
    "PCE_actuals = df.drop(columns=PCEPI_cols_list) #remove identified columns\n",
    "PCE_actuals['Prev PCE Pct Chg'] = PCE_actuals['Curr PCE Pct Chg'].shift() #create lag of Current values for Previous\n",
    "PCE_actuals = PCE_actuals[PCE_actuals['Prev PCE Pct Chg'].notna()] #remove unpopulated data after lag\n",
    "PCE_actuals = PCE_actuals.shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period) \n",
    "PCE_actuals = PCE_actuals[['Prev PCE Pct Chg', 'Curr PCE Pct Chg']] #set order of columns\n",
    "PCE_actuals = PCE_actuals.loc['2007-03-31':] #remove unpopulated data\n",
    "PCE_actuals.index = PCE_actuals.index.to_period(\"Q\") #format index\n",
    "PCE_actuals.index.rename('Period', inplace = True) #rename index\n",
    "PCE_actuals.dropna(subset=['Curr PCE Pct Chg'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format US Economic Policy Uncertainty Index Data from ALFRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://alfred.stlouisfed.org/series/downloaddata?seid=USEPUINDXD\n",
    "#Note: Cannot select all here as too many vintages exists.\n",
    "#      Vintages for this script are 'beginning - 2017-12-29' and '2018-01-03 - Current'\n",
    "#      EPU also has a Categorical dataset which has a items that we could combine to filter out monetary policy\n",
    "\n",
    "# open workbooks\n",
    "xls1 = pd.ExcelFile('USEPUINDXD_2 - 2014 - 2017-12-29.xls')\n",
    "xls2 = pd.ExcelFile('USEPUINDXD_2 - 2018 - Current.xls')\n",
    "\n",
    "# store files' contents in dictionaries\n",
    "EPU_dict = pd.read_excel(xls1, sheet_name=None)\n",
    "EPU_dict2 = pd.read_excel(xls2, sheet_name=None)\n",
    "\n",
    "# combine dictionaries \n",
    "EPU_dict.update(EPU_dict2)\n",
    "\n",
    "# set index of all Vintage dataframes in dict.values to the observation date column\n",
    "[EPU_dict[i].set_index('observation_date', inplace=True) for i in EPU_dict.keys() \n",
    "     if i[0:7]=='Vintage']\n",
    "\n",
    "# find the index from one of the vintage dataframes\n",
    "df_index = find_index_in_Excel_File_dict(EPU_dict)\n",
    "\n",
    "# initialize a new df with the index found above\n",
    "EPU_df = pd.DataFrame(index=df_index)\n",
    "\n",
    "# combine vintage dfs into master df\n",
    "for key, value in EPU_dict.items():\n",
    "    if key[0:7] == 'Vintage':\n",
    "        EPU_df = EPU_df.join(EPU_dict1[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPU_df_copy = EPU_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USEPUINDXD_20140327</th>\n",
       "      <th>USEPUINDXD_20140328</th>\n",
       "      <th>USEPUINDXD_20140331</th>\n",
       "      <th>USEPUINDXD_20140401</th>\n",
       "      <th>USEPUINDXD_20140402</th>\n",
       "      <th>USEPUINDXD_20140403</th>\n",
       "      <th>USEPUINDXD_20140404</th>\n",
       "      <th>USEPUINDXD_20140407</th>\n",
       "      <th>USEPUINDXD_20140408</th>\n",
       "      <th>USEPUINDXD_20140409</th>\n",
       "      <th>...</th>\n",
       "      <th>USEPUINDXD_20201231</th>\n",
       "      <th>USEPUINDXD_20210104</th>\n",
       "      <th>USEPUINDXD_20210105</th>\n",
       "      <th>USEPUINDXD_20210106</th>\n",
       "      <th>USEPUINDXD_20210107</th>\n",
       "      <th>USEPUINDXD_20210108</th>\n",
       "      <th>USEPUINDXD_20210111</th>\n",
       "      <th>USEPUINDXD_20210112</th>\n",
       "      <th>USEPUINDXD_20210113</th>\n",
       "      <th>USEPUINDXD_20210114</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>68.03945</td>\n",
       "      <td>68.03945</td>\n",
       "      <td>68.03945</td>\n",
       "      <td>68.03945</td>\n",
       "      <td>68.03945</td>\n",
       "      <td>68.03945</td>\n",
       "      <td>68.03945</td>\n",
       "      <td>68.03945</td>\n",
       "      <td>68.03945</td>\n",
       "      <td>68.03945</td>\n",
       "      <td>...</td>\n",
       "      <td>68.04</td>\n",
       "      <td>68.04</td>\n",
       "      <td>68.04</td>\n",
       "      <td>68.04</td>\n",
       "      <td>68.04</td>\n",
       "      <td>68.04</td>\n",
       "      <td>68.04</td>\n",
       "      <td>68.04</td>\n",
       "      <td>68.04</td>\n",
       "      <td>68.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>119.35917</td>\n",
       "      <td>119.35917</td>\n",
       "      <td>119.35917</td>\n",
       "      <td>119.35917</td>\n",
       "      <td>119.35917</td>\n",
       "      <td>119.35917</td>\n",
       "      <td>119.35917</td>\n",
       "      <td>119.35917</td>\n",
       "      <td>119.35917</td>\n",
       "      <td>119.35917</td>\n",
       "      <td>...</td>\n",
       "      <td>119.36</td>\n",
       "      <td>119.36</td>\n",
       "      <td>119.36</td>\n",
       "      <td>119.36</td>\n",
       "      <td>119.36</td>\n",
       "      <td>119.36</td>\n",
       "      <td>119.36</td>\n",
       "      <td>119.36</td>\n",
       "      <td>119.36</td>\n",
       "      <td>119.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>35.73232</td>\n",
       "      <td>35.73232</td>\n",
       "      <td>35.73232</td>\n",
       "      <td>35.73232</td>\n",
       "      <td>35.73232</td>\n",
       "      <td>35.73232</td>\n",
       "      <td>35.73232</td>\n",
       "      <td>35.73232</td>\n",
       "      <td>35.73232</td>\n",
       "      <td>35.73232</td>\n",
       "      <td>...</td>\n",
       "      <td>35.73</td>\n",
       "      <td>35.73</td>\n",
       "      <td>35.73</td>\n",
       "      <td>35.73</td>\n",
       "      <td>35.73</td>\n",
       "      <td>35.73</td>\n",
       "      <td>35.73</td>\n",
       "      <td>35.73</td>\n",
       "      <td>35.73</td>\n",
       "      <td>35.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>109.30513</td>\n",
       "      <td>109.30513</td>\n",
       "      <td>109.30513</td>\n",
       "      <td>109.30513</td>\n",
       "      <td>109.30513</td>\n",
       "      <td>109.30513</td>\n",
       "      <td>109.30513</td>\n",
       "      <td>109.30513</td>\n",
       "      <td>109.30513</td>\n",
       "      <td>109.30513</td>\n",
       "      <td>...</td>\n",
       "      <td>109.31</td>\n",
       "      <td>109.31</td>\n",
       "      <td>109.31</td>\n",
       "      <td>109.31</td>\n",
       "      <td>109.31</td>\n",
       "      <td>109.31</td>\n",
       "      <td>109.31</td>\n",
       "      <td>109.31</td>\n",
       "      <td>109.31</td>\n",
       "      <td>109.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>123.22074</td>\n",
       "      <td>123.22074</td>\n",
       "      <td>123.22074</td>\n",
       "      <td>123.22074</td>\n",
       "      <td>123.22074</td>\n",
       "      <td>123.22074</td>\n",
       "      <td>123.22074</td>\n",
       "      <td>123.22074</td>\n",
       "      <td>123.22074</td>\n",
       "      <td>123.22074</td>\n",
       "      <td>...</td>\n",
       "      <td>123.22</td>\n",
       "      <td>123.22</td>\n",
       "      <td>123.22</td>\n",
       "      <td>123.22</td>\n",
       "      <td>123.22</td>\n",
       "      <td>123.22</td>\n",
       "      <td>123.22</td>\n",
       "      <td>123.22</td>\n",
       "      <td>123.22</td>\n",
       "      <td>123.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.08</td>\n",
       "      <td>128.46</td>\n",
       "      <td>142.67</td>\n",
       "      <td>141.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297.15</td>\n",
       "      <td>279.25</td>\n",
       "      <td>290.29</td>\n",
       "      <td>290.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.47</td>\n",
       "      <td>341.95</td>\n",
       "      <td>325.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.29</td>\n",
       "      <td>229.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>194.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7684 rows Ã— 1724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  USEPUINDXD_20140327  USEPUINDXD_20140328  \\\n",
       "observation_date                                             \n",
       "2000-01-01                   68.03945             68.03945   \n",
       "2000-01-02                  119.35917            119.35917   \n",
       "2000-01-03                   35.73232             35.73232   \n",
       "2000-01-04                  109.30513            109.30513   \n",
       "2000-01-05                  123.22074            123.22074   \n",
       "...                               ...                  ...   \n",
       "2021-01-09                        NaN                  NaN   \n",
       "2021-01-10                        NaN                  NaN   \n",
       "2021-01-11                        NaN                  NaN   \n",
       "2021-01-12                        NaN                  NaN   \n",
       "2021-01-13                        NaN                  NaN   \n",
       "\n",
       "                  USEPUINDXD_20140331  USEPUINDXD_20140401  \\\n",
       "observation_date                                             \n",
       "2000-01-01                   68.03945             68.03945   \n",
       "2000-01-02                  119.35917            119.35917   \n",
       "2000-01-03                   35.73232             35.73232   \n",
       "2000-01-04                  109.30513            109.30513   \n",
       "2000-01-05                  123.22074            123.22074   \n",
       "...                               ...                  ...   \n",
       "2021-01-09                        NaN                  NaN   \n",
       "2021-01-10                        NaN                  NaN   \n",
       "2021-01-11                        NaN                  NaN   \n",
       "2021-01-12                        NaN                  NaN   \n",
       "2021-01-13                        NaN                  NaN   \n",
       "\n",
       "                  USEPUINDXD_20140402  USEPUINDXD_20140403  \\\n",
       "observation_date                                             \n",
       "2000-01-01                   68.03945             68.03945   \n",
       "2000-01-02                  119.35917            119.35917   \n",
       "2000-01-03                   35.73232             35.73232   \n",
       "2000-01-04                  109.30513            109.30513   \n",
       "2000-01-05                  123.22074            123.22074   \n",
       "...                               ...                  ...   \n",
       "2021-01-09                        NaN                  NaN   \n",
       "2021-01-10                        NaN                  NaN   \n",
       "2021-01-11                        NaN                  NaN   \n",
       "2021-01-12                        NaN                  NaN   \n",
       "2021-01-13                        NaN                  NaN   \n",
       "\n",
       "                  USEPUINDXD_20140404  USEPUINDXD_20140407  \\\n",
       "observation_date                                             \n",
       "2000-01-01                   68.03945             68.03945   \n",
       "2000-01-02                  119.35917            119.35917   \n",
       "2000-01-03                   35.73232             35.73232   \n",
       "2000-01-04                  109.30513            109.30513   \n",
       "2000-01-05                  123.22074            123.22074   \n",
       "...                               ...                  ...   \n",
       "2021-01-09                        NaN                  NaN   \n",
       "2021-01-10                        NaN                  NaN   \n",
       "2021-01-11                        NaN                  NaN   \n",
       "2021-01-12                        NaN                  NaN   \n",
       "2021-01-13                        NaN                  NaN   \n",
       "\n",
       "                  USEPUINDXD_20140408  USEPUINDXD_20140409  ...  \\\n",
       "observation_date                                            ...   \n",
       "2000-01-01                   68.03945             68.03945  ...   \n",
       "2000-01-02                  119.35917            119.35917  ...   \n",
       "2000-01-03                   35.73232             35.73232  ...   \n",
       "2000-01-04                  109.30513            109.30513  ...   \n",
       "2000-01-05                  123.22074            123.22074  ...   \n",
       "...                               ...                  ...  ...   \n",
       "2021-01-09                        NaN                  NaN  ...   \n",
       "2021-01-10                        NaN                  NaN  ...   \n",
       "2021-01-11                        NaN                  NaN  ...   \n",
       "2021-01-12                        NaN                  NaN  ...   \n",
       "2021-01-13                        NaN                  NaN  ...   \n",
       "\n",
       "                  USEPUINDXD_20201231  USEPUINDXD_20210104  \\\n",
       "observation_date                                             \n",
       "2000-01-01                      68.04                68.04   \n",
       "2000-01-02                     119.36               119.36   \n",
       "2000-01-03                      35.73                35.73   \n",
       "2000-01-04                     109.31               109.31   \n",
       "2000-01-05                     123.22               123.22   \n",
       "...                               ...                  ...   \n",
       "2021-01-09                        NaN                  NaN   \n",
       "2021-01-10                        NaN                  NaN   \n",
       "2021-01-11                        NaN                  NaN   \n",
       "2021-01-12                        NaN                  NaN   \n",
       "2021-01-13                        NaN                  NaN   \n",
       "\n",
       "                  USEPUINDXD_20210105  USEPUINDXD_20210106  \\\n",
       "observation_date                                             \n",
       "2000-01-01                      68.04                68.04   \n",
       "2000-01-02                     119.36               119.36   \n",
       "2000-01-03                      35.73                35.73   \n",
       "2000-01-04                     109.31               109.31   \n",
       "2000-01-05                     123.22               123.22   \n",
       "...                               ...                  ...   \n",
       "2021-01-09                        NaN                  NaN   \n",
       "2021-01-10                        NaN                  NaN   \n",
       "2021-01-11                        NaN                  NaN   \n",
       "2021-01-12                        NaN                  NaN   \n",
       "2021-01-13                        NaN                  NaN   \n",
       "\n",
       "                  USEPUINDXD_20210107  USEPUINDXD_20210108  \\\n",
       "observation_date                                             \n",
       "2000-01-01                      68.04                68.04   \n",
       "2000-01-02                     119.36               119.36   \n",
       "2000-01-03                      35.73                35.73   \n",
       "2000-01-04                     109.31               109.31   \n",
       "2000-01-05                     123.22               123.22   \n",
       "...                               ...                  ...   \n",
       "2021-01-09                        NaN                  NaN   \n",
       "2021-01-10                        NaN                  NaN   \n",
       "2021-01-11                        NaN                  NaN   \n",
       "2021-01-12                        NaN                  NaN   \n",
       "2021-01-13                        NaN                  NaN   \n",
       "\n",
       "                  USEPUINDXD_20210111  USEPUINDXD_20210112  \\\n",
       "observation_date                                             \n",
       "2000-01-01                      68.04                68.04   \n",
       "2000-01-02                     119.36               119.36   \n",
       "2000-01-03                      35.73                35.73   \n",
       "2000-01-04                     109.31               109.31   \n",
       "2000-01-05                     123.22               123.22   \n",
       "...                               ...                  ...   \n",
       "2021-01-09                     136.08               128.46   \n",
       "2021-01-10                     297.15               279.25   \n",
       "2021-01-11                        NaN               435.47   \n",
       "2021-01-12                        NaN                  NaN   \n",
       "2021-01-13                        NaN                  NaN   \n",
       "\n",
       "                  USEPUINDXD_20210113  USEPUINDXD_20210114  \n",
       "observation_date                                            \n",
       "2000-01-01                      68.04                68.04  \n",
       "2000-01-02                     119.36               119.36  \n",
       "2000-01-03                      35.73                35.73  \n",
       "2000-01-04                     109.31               109.31  \n",
       "2000-01-05                     123.22               123.22  \n",
       "...                               ...                  ...  \n",
       "2021-01-09                     142.67               141.50  \n",
       "2021-01-10                     290.29               290.14  \n",
       "2021-01-11                     341.95               325.10  \n",
       "2021-01-12                     190.29               229.14  \n",
       "2021-01-13                        NaN               194.95  \n",
       "\n",
       "[7684 rows x 1724 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPU_df_copy = EPU_df_copy.loc['2000-01-01':] #filter extra data\n",
    "# df = df.resample('Q').sum(min_count=3)/3 #resample monthly data to quarterly to match Philly convention\n",
    "# df['Curr PCE Pct Chg'] = find_new_obs_percent_chg(df, 1, 1) #find vintage percent changes to match Philly convention \n",
    "# PCEPI_cols_list = find_target_columns(df, 0, 5, 'PCEPI') #identify columns to remove\n",
    "# PCE_actuals = df.drop(columns=PCEPI_cols_list) #remove identified columns\n",
    "# PCE_actuals['Prev PCE Pct Chg'] = PCE_actuals['Curr PCE Pct Chg'].shift() #create lag of Current values for Previous\n",
    "# PCE_actuals = PCE_actuals[PCE_actuals['Prev PCE Pct Chg'].notna()] #remove unpopulated data after lag\n",
    "# PCE_actuals = PCE_actuals.shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period) \n",
    "# PCE_actuals = PCE_actuals[['Prev PCE Pct Chg', 'Curr PCE Pct Chg']] #set order of columns\n",
    "# PCE_actuals = PCE_actuals.loc['2007-03-31':] #remove unpopulated data\n",
    "# PCE_actuals.index = PCE_actuals.index.to_period(\"Q\") #format index\n",
    "# PCE_actuals.index.rename('Period', inplace = True) #rename index\n",
    "# PCE_actuals.dropna(subset=['Curr PCE Pct Chg'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Mean GDP Forecast Data from FRB Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\miniconda3\\envs\\FOMC\\lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    }
   ],
   "source": [
    "#URL: https://www.philadelphiafed.org/surveys-and-data/rgdp\n",
    "#Note: 'Mean Responses' as of 1/10/2021\n",
    "df = pd.read_excel(io='Mean_RGDP_Level.xlsx', sheet_name='Mean_Level') #read in data\n",
    "df = df[df['YEAR'].notna()] #drop last col which shows up as NaT in index (not sure why this shows up...)\n",
    "df['YEAR'] = df['YEAR'].astype(int).astype(str) #cast year to string for Period index\n",
    "df['QUARTER'] = df['QUARTER'].astype(int).astype(str) #cast quarter to string for Period index\n",
    "df['Period'] = df[['YEAR', 'QUARTER']].agg('-Q'.join, axis=1) #combine year and quarter data into Period\n",
    "df['Period'] = pd.to_datetime(df['Period']) #set Period to datetime\n",
    "df.set_index('Period', inplace=True) #set Period as df index\n",
    "df.index = df.index.to_period(\"Q\") #format index\n",
    "GDP_cols_list = ['RGDP1', 'RGDP2', 'RGDP3'] #identify columns we want to retain and lag\n",
    "df = df.filter(GDP_cols_list, axis=1) #retain columns we want\n",
    "df[GDP_cols_list] = df[GDP_cols_list].shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period\n",
    "df = df[df['RGDP1'].notna()] #remove rows where RGDP1 has NaN\n",
    "df['1Q Ahead Mean GDP Forecast'] = df[['RGDP1', 'RGDP2']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast 1evels \n",
    "df['2Q Ahead Mean GDP Forecast'] = df[['RGDP2', 'RGDP3']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast levels \n",
    "mean_GDP_forecasts = ['1Q Ahead Mean GDP Forecast', '2Q Ahead Mean GDP Forecast'] #identify columns to retain\n",
    "mean_GDP_forecasts = df.filter(mean_GDP_forecasts, axis=1) #filter for wanted columns\n",
    "# mean_GDP_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Median GDP Forecast Data from FRB Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://www.philadelphiafed.org/surveys-and-data/rgdp\n",
    "#Note: 'Median Responses' as of 1/10/2021\n",
    "df = pd.read_excel(io='Median_RGDP_Level.xlsx', sheet_name='Median_Level') #read in data\n",
    "df = df[df['YEAR'].notna()] #drop last col which shows up as NaT in index (not sure why this shows up...)\n",
    "df['YEAR'] = df['YEAR'].astype(int).astype(str) #cast year to string for Period index\n",
    "df['QUARTER'] = df['QUARTER'].astype(int).astype(str) #cast quarter to string for Period index\n",
    "df['Period'] = df[['YEAR', 'QUARTER']].agg('-Q'.join, axis=1) #combine year and quarter data into Period\n",
    "df['Period'] = pd.to_datetime(df['Period']) #set Period to datetime\n",
    "df.set_index('Period', inplace=True) #set Period as df index\n",
    "df.index = df.index.to_period(\"Q\") #format index\n",
    "GDP_cols_list = ['RGDP1', 'RGDP2', 'RGDP3'] #identify columns we want to retain and lag\n",
    "df = df.filter(GDP_cols_list, axis=1) #retain columns we want\n",
    "df[GDP_cols_list] = df[GDP_cols_list].shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period) \n",
    "df = df[df['RGDP1'].notna()] #remove rows where RGDP1 has NaN\n",
    "df['1Q Ahead Median GDP Forecast'] = df[['RGDP1', 'RGDP2']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast 1\n",
    "df['2Q Ahead Median GDP Forecast'] = df[['RGDP2', 'RGDP3']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast 1\n",
    "median_GDP_forecasts = ['1Q Ahead Median GDP Forecast', '2Q Ahead Median GDP Forecast'] #identify columns to retain\n",
    "median_GDP_forecasts = df.filter(median_GDP_forecasts, axis=1) #filter for wanted columns\n",
    "# median_GDP_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Mean GDP Price Index Forecast Data from FRB Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://www.philadelphiafed.org/surveys-and-data/pgdp\n",
    "#Note: 'Mean Responses' as of 1/12/2021\n",
    "df = pd.read_excel(io='Mean_PGDP_Level.xlsx', sheet_name='Mean_Level') #read in data\n",
    "df = df[df['YEAR'].notna()] #drop last col which shows up as NaT in index (not sure why this shows up...)\n",
    "df['YEAR'] = df['YEAR'].astype(int).astype(str) #cast year to string for Period index\n",
    "df['QUARTER'] = df['QUARTER'].astype(int).astype(str) #cast quarter to string for Period index\n",
    "df['Period'] = df[['YEAR', 'QUARTER']].agg('-Q'.join, axis=1) #combine year and quarter data into Period\n",
    "df['Period'] = pd.to_datetime(df['Period']) #set Period to datetime\n",
    "df.set_index('Period', inplace=True) #set Period as df index\n",
    "df.index = df.index.to_period(\"Q\") #format index\n",
    "PGDP_cols_list = ['PGDP1', 'PGDP2', 'PGDP3'] #identify columns we want to retain and lag\n",
    "df = df.filter(PGDP_cols_list, axis=1) #retain columns we want\n",
    "df[PGDP_cols_list] = df[PGDP_cols_list].shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period\n",
    "df = df[df['PGDP1'].notna()] #remove rows where RGDP1 has NaN\n",
    "df['1Q Ahead Mean GDP Price Forecast'] = df[['PGDP1', 'PGDP2']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast 1evels \n",
    "df['2Q Ahead Mean GDP Price Forecast'] = df[['PGDP2', 'PGDP3']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast levels \n",
    "mean_PGDP_forecasts = ['1Q Ahead Mean GDP Price Forecast', '2Q Ahead Mean GDP Price Forecast'] #identify columns to retain\n",
    "mean_PGDP_forecasts = df.filter(mean_PGDP_forecasts, axis=1) #filter for wanted columns\n",
    "# mean_PGDP_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Median GDP Price Index Forecast Data from FRB Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://www.philadelphiafed.org/surveys-and-data/pgdp\n",
    "#Note: 'Median Responses' as of 1/12/2021\n",
    "df = pd.read_excel(io='Median_PGDP_Level.xlsx', sheet_name='Median_Level') #read in data\n",
    "#print(df)\n",
    "df = df[df['YEAR'].notna()] #drop last col which shows up as NaT in index (not sure why this shows up...)\n",
    "df['YEAR'] = df['YEAR'].astype(int).astype(str) #cast year to string for Period index\n",
    "df['QUARTER'] = df['QUARTER'].astype(int).astype(str) #cast quarter to string for Period index\n",
    "df['Period'] = df[['YEAR', 'QUARTER']].agg('-Q'.join, axis=1) #combine year and quarter data into Period\n",
    "df['Period'] = pd.to_datetime(df['Period']) #set Period to datetime\n",
    "df.set_index('Period', inplace=True) #set Period as df index\n",
    "df.index = df.index.to_period(\"Q\") #format index\n",
    "PGDP_cols_list = ['PGDP1', 'PGDP2', 'PGDP3'] #identify columns we want to retain and lag\n",
    "df = df.filter(PGDP_cols_list, axis=1) #retain columns we want\n",
    "df[PGDP_cols_list] = df[PGDP_cols_list].shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period\n",
    "df = df[df['PGDP1'].notna()] #remove rows where RGDP1 has NaN\n",
    "df['1Q Ahead Median GDP Price Forecast'] = df[['PGDP1', 'PGDP2']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast 1evels \n",
    "df['2Q Ahead Median GDP Price Forecast'] = df[['PGDP2', 'PGDP3']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast levels \n",
    "median_PGDP_forecasts = ['1Q Ahead Median GDP Price Forecast', '2Q Ahead Median GDP Price Forecast'] #identify columns to retain\n",
    "median_PGDP_forecasts = df.filter(median_PGDP_forecasts, axis=1) #filter for wanted columns\n",
    "# median_PGDP_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Mean PCE Forecast Data from FRB Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://www.philadelphiafed.org/surveys-and-data/corepce\n",
    "#Note: 'Mean Responses' as of 1/10/2021\n",
    "df = pd.read_excel(io='Mean_COREPCE_Level.xlsx', sheet_name='Mean_Level') #read in data\n",
    "df = df[df['YEAR'].notna()] #drop last col which shows up as NaT in index (not sure why this shows up...)\n",
    "df['YEAR'] = df['YEAR'].astype(int).astype(str) #cast year to string for Period index\n",
    "df['QUARTER'] = df['QUARTER'].astype(int).astype(str) #cast quarter to string for Period index\n",
    "df['Period'] = df[['YEAR', 'QUARTER']].agg('-Q'.join, axis=1) #combine year and quarter data into Period\n",
    "df['Period'] = pd.to_datetime(df['Period']) #set Period to datetime\n",
    "df.set_index('Period', inplace=True) #set Period as df index\n",
    "df.index = df.index.to_period(\"Q\") #format index\n",
    "PCE_cols_list = ['COREPCE1', 'COREPCE2', 'COREPCE3'] #identify columns we want to retain and lag\n",
    "df[PCE_cols_list] = df[PCE_cols_list].shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period\n",
    "df = df[df['COREPCE1'].notna()] #remove rows where COREPCE1 has NaN\n",
    "df = df.filter(PCE_cols_list, axis=1) #retain columns we want\n",
    "df.rename(columns={'COREPCE1':'COREPCE - Mean','COREPCE2':'1Q Ahead Mean PCE Forecast','COREPCE3':'2Q Ahead Mean PCE Forecast'}, inplace=True) #rename column\n",
    "mean_PCE_forecasts = ['COREPCE - Mean', '1Q Ahead Mean PCE Forecast', '2Q Ahead Mean PCE Forecast'] #identify columns to retain *keeping mean for actuals comparison* \n",
    "mean_PCE_forecasts = df.filter(mean_PCE_forecasts, axis=1) #filter for wanted columns\n",
    "# mean_PCE_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Median PCE Forecast Data from FRB Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://www.philadelphiafed.org/surveys-and-data/corepce\n",
    "#Note: 'Median Responses' as of 1/10/2021\n",
    "df = pd.read_excel(io='Median_COREPCE_Level.xlsx', sheet_name='Median_Level') #read data\n",
    "df = df[df['YEAR'].notna()] #drop last col which shows up as NaT in index (not sure why this shows up...)\n",
    "df['YEAR'] = df['YEAR'].fillna(0.0).astype(int).astype(str) #cast year to string for Period index\n",
    "df['QUARTER'] = df['QUARTER'].fillna(0.0).astype(int).astype(str) #cast quarter to string for Period index\n",
    "df['Period'] = df[['YEAR', 'QUARTER']].agg('-Q'.join, axis=1) #combine year and quarter data into Period\n",
    "df['Period'] = pd.to_datetime(df['Period']) #set Period to datetime\n",
    "df.set_index('Period', inplace=True) #set Period as df index\n",
    "df.index = df.index.to_period(\"Q\") #format index\n",
    "PCE_cols_list = ['COREPCE1', 'COREPCE2', 'COREPCE3'] #identify columns we want to retain and lag\n",
    "df[PCE_cols_list] = df[PCE_cols_list].shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period\n",
    "df = df[df['COREPCE1'].notna()] #remove rows where COREPCE1 has NaN\n",
    "df = df.filter(PCE_cols_list, axis=1) #retain columns we want\n",
    "df.rename(columns={'COREPCE1':'COREPCE - Median','COREPCE2':'1Q Ahead Median PCE Forecast','COREPCE3':'2Q Ahead Median PCE Forecast'}, inplace=True) #rename column\n",
    "median_PCE_forecasts = ['COREPCE - Median', '1Q Ahead Median PCE Forecast', '2Q Ahead Median PCE Forecast']\n",
    "median_PCE_forecasts = df.filter(median_PCE_forecasts, axis=1)\n",
    "# median_PCE_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format S&P500 Data from Yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format US Political Uncertainty Index Data from ALFRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine GDP Data from ALFRED & Philly Fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_data = GDP_actuals.join(mean_GDP_forecasts) #left join the GDP_acuals and mean_GDP_forecasts\n",
    "GDP_data = GDP_data.join(median_GDP_forecasts) #left join the GDP_acuals and median_GDP_forecasts\n",
    "GDP_data = GDP_data.loc['2000Q1':] #remove rows outside of our period\n",
    "GDP_data.index = GDP_data.index.strftime('%m/%d/%Y') #set index format to m/d/yyyy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine PCE Data from ALFRED & Philly Fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PCE_forecasts = mean_PCE_forecasts.join(median_PCE_forecasts)\n",
    "PCE_data = PCE_actuals.join(PCE_forecasts)\n",
    "# # Test for data continuity\n",
    "# print('Corr Median & FRED Actual', PCE_data['Curr PCE Pct Chg'].corr(PCE_data['COREPCE - Median'])) #check for data continuity across the FRED actual and Philly Fed forcast data\n",
    "# print('Corr Median & FRED Actual', PCE_data['Curr PCE Pct Chg'].corr(PCE_data['COREPCE - Mean'])) #check for data continuity across the FRED actual and Philly Fed forcast data\n",
    "PCE_data_to_drop = ['COREPCE - Median','COREPCE - Mean']\n",
    "PCE_data = PCE_data.drop(PCE_data_to_drop, axis=1)\n",
    "PCE_data.index = PCE_data.index.strftime('%m/%d/%Y') #set index format to m/d/yyyy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine PGDP Data from ALFRED & Philly Fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PGDP_forecasts = mean_PGDP_forecasts.join(median_PGDP_forecasts)\n",
    "PGDP_data = PGDP_actuals.join(PGDP_forecasts)\n",
    "PGDP_data = PGDP_data.loc['2000Q1':] #remove rows outside of our period\n",
    "PGDP_data.index = PGDP_data.index.strftime('%m/%d/%Y') #set index format to m/d/yyyy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Datasets for Shock Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Miles, this one is for you. Call the ball. :)\n",
    "'''\n",
    "\n",
    "macro_data = GDP_data.join(PGDP_data)\n",
    "# macro_data\n",
    "# macro_data.to_csv('macro_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
