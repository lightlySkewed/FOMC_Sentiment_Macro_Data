{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo:\n",
    "\n",
    "Plot important dates against our output: https://www.policyuncertainty.com/media/US_Annotated_Series.pdf\n",
    "\n",
    "1) Bush Election\n",
    "2) 9/11\n",
    "3) Gulf War II\n",
    "4) Stimulus Debate ~2007/ 2008\n",
    "5) Lehman/ TARP ~2008/ 2009\n",
    "6) Eurozone Crisis/ US Midterm Elections ~Nov 2010\n",
    "7) Debt Ceiling Debate ~2011/2012\n",
    "8) Fiscal Cliff ~2013\n",
    "9) Govt. Shutdown ~2013/ 2014\n",
    "10) Brexit ~2016\n",
    "11) Trump Election ~Nov 2016\n",
    "12) US out of TPP ~2016/ 2017\n",
    "13) Tarrifs 2018\n",
    "\n",
    "Market Dates: https://www.timetoast.com/timelines/important-dates-in-the-history-of-the-u-s-stock-markets\n",
    "\n",
    "1) Dot Com Bubble = Mar 10, 2000\n",
    "2) NASDAQ Drop 356 Points = Apr 14, 2000\n",
    "3) Hurricane Katrina = Aug 25, 2005\n",
    "4) 2008 Market Selloff = 09/29/2008, 10/08/2008, 10/15/2008, 10/22/2008, 12/01/2008, 12/10/2008\n",
    "5) 2011 Market Selloff = 08/04/2011, 08/08/2011, 09/17/2011, 12/31/2011\n",
    "6) Derive other dates from SPX data\n",
    "\n",
    "https://fraser.stlouisfed.org/timeline/covid-19-pandemic\n",
    "\n",
    "https://fraser.stlouisfed.org/timeline/financial-crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False #for intellisense compatibility w/ Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipdb\n",
    "import copy\n",
    "import datetime as dt\n",
    "from iGetByWithALittle import find_target_columns, find_new_obs_percent_chg, find_new_vintage_percent_chg, find_index_in_Excel_File_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in FOMC Meeting Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fomc_dates.csv')\n",
    "FOMC_meets = df['fomc_date'].tolist()\n",
    "FOMC_dates = [dt.datetime.strptime(meet,'%m/%d/%Y') for meet in FOMC_meets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Vintage GDP Data from ALFRED File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdp-1</th>\n",
       "      <th>gdp-0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-02-02</th>\n",
       "      <td>1.389743</td>\n",
       "      <td>1.419005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-21</th>\n",
       "      <td>1.389743</td>\n",
       "      <td>1.688650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-16</th>\n",
       "      <td>1.772562</td>\n",
       "      <td>1.321206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-28</th>\n",
       "      <td>1.772562</td>\n",
       "      <td>1.322312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-22</th>\n",
       "      <td>1.338910</td>\n",
       "      <td>1.272874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-15</th>\n",
       "      <td>0.521779</td>\n",
       "      <td>0.519729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>0.521779</td>\n",
       "      <td>0.527469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-10</th>\n",
       "      <td>0.527469</td>\n",
       "      <td>-1.286382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-29</th>\n",
       "      <td>0.527469</td>\n",
       "      <td>-1.272539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16</th>\n",
       "      <td>-1.272539</td>\n",
       "      <td>-9.093019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               gdp-1     gdp-0\n",
       "2000-02-02  1.389743  1.419005\n",
       "2000-03-21  1.389743  1.688650\n",
       "2000-05-16  1.772562  1.321206\n",
       "2000-06-28  1.772562  1.322312\n",
       "2000-08-22  1.338910  1.272874\n",
       "...              ...       ...\n",
       "2020-03-15  0.521779  0.519729\n",
       "2020-04-29  0.521779  0.527469\n",
       "2020-06-10  0.527469 -1.286382\n",
       "2020-07-29  0.527469 -1.272539\n",
       "2020-09-16 -1.272539 -9.093019\n",
       "\n",
       "[176 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL: https://alfred.stlouisfed.org/series/downloaddata?seid=GDPC1\n",
    "# Note: Must select 'All' in the Vintage Dates section. Data as of 1/28/2021\n",
    "\n",
    "# read in FRED data\n",
    "df = pd.read_csv('GDPC1_2_Vintages_Starting_1991_12_04.txt', sep='\\t', na_values='.')\n",
    "\n",
    "# set index to observation date\n",
    "df.set_index('observation_date', inplace=True)\n",
    "\n",
    "# discard data prior to 1999 as our FOMC data begin in 2000\n",
    "df = df.loc['1999-01-01':]\n",
    "\n",
    "# drop any remaining columns with no observations\n",
    "df = df.dropna(how='all', axis=1)\n",
    "\n",
    "# calculate vintage percent changes with helper function\n",
    "vintage_gdp_changes = find_new_vintage_percent_chg(df, FOMC_dates, column_A_name='gdp-1', column_B_name='gdp-0')\n",
    "vintage_gdp_changes.to_csv('vintage_gdp_changes.csv')\n",
    "vintage_gdp_changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Vintage GDP Chain-Type Price Index Data from ALFRED File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://alfred.stlouisfed.org/series/downloaddata?seid=GDPCTPI\n",
    "#NOTE: Must select 'All' in the Vintage Dates section. Data as of 1/28/2021\n",
    "\n",
    "# read in FRED data\n",
    "df = pd.read_csv('GDPCTPI_2_Vintages_Starting_1996_01_19.txt', sep='\\t', na_values='.')\n",
    "\n",
    "# set index to observation date\n",
    "df.set_index('observation_date', inplace=True)\n",
    "\n",
    "#discard data prior to 1999 as our FOMC data begins in 2000\n",
    "df = df.loc['1999-01-01':]\n",
    "\n",
    "# drop any remaining columns with no observations\n",
    "df = df.dropna(how='all', axis=1)\n",
    "\n",
    "vintage_gdp_price_changes = find_new_vintage_percent_chg(df, FOMC_dates, column_A_name='price-1', column_B_name='price-0')\n",
    "vintage_gdp_price_changes.to_csv('vintage_gdp_price_changes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format US Economic Policy Uncertainty Index Data from ALFRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://alfred.stlouisfed.org/series/downloaddata?seid=USEPUINDXD\n",
    "#Note: Cannot select all here as too many vintages exists. Data as of 1/28/2021.\n",
    "# These data don't strongly revise so we calculate on the latest vintage\n",
    "\n",
    "# read in FRED data\n",
    "df = pd.read_csv('USEPUINDXD_2_Vintages_Starting_2018_06_29.txt', sep='\\t', na_values='.')\n",
    "\n",
    "# set index to observation date\n",
    "df.set_index('observation_date', inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.iloc[:, -1:]\n",
    "df = df.rename(columns={'USEPUINDXD_20210128': 'EPU'})\n",
    "df['EPU 30 Day MA'] = df.rolling(window=30)['EPU'].mean()\n",
    "df['EPU Std 30 Day MA'] = StandardScaler().fit_transform(df[['EPU 30 Day MA']])\n",
    "\n",
    "epu_df = df[['EPU Std 30 Day MA']]\n",
    "# epu_df.to_csv('epu_df.csv')\n",
    "\n",
    "FOMC_df = pd.DataFrame(index=FOMC_meets)\n",
    "FOMC_df.index = pd.to_datetime(FOMC_df.index)\n",
    "FOMC_df.index.name = 'observation_date'\n",
    "\n",
    "FOMC_epu = pd.merge_asof(FOMC_df, epu_df, on = 'observation_date')\n",
    "FOMC_epu.set_index('observation_date', inplace=True)\n",
    "# FOMC_epu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format S&P 500 Data from Yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('^GSPC.csv')\n",
    "df.set_index('Date', inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.rename(columns={'Close': 'SPX'})\n",
    "df['SPX 30 Day MA'] = df.rolling(window=30)['SPX'].mean()\n",
    "df['SPX Std 30 Day MA'] = StandardScaler().fit_transform(df[['SPX 30 Day MA']])\n",
    "\n",
    "\n",
    "df.index.name = 'observation_date'\n",
    "spx_df = df[['SPX Std 30 Day MA']]\n",
    "\n",
    "FOMC_spx = pd.merge_asof(FOMC_df, spx_df, on = 'observation_date')\n",
    "FOMC_spx.set_index('observation_date', inplace=True)\n",
    "# FOMC_spx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Mean GDP Forecast Data from FRB Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\miniconda3\\envs\\FOMC\\lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    }
   ],
   "source": [
    "#URL: https://www.philadelphiafed.org/surveys-and-data/rgdp\n",
    "#Note: 'Mean Responses' as of 1/10/2021\n",
    "df = pd.read_excel(io='Mean_RGDP_Level.xlsx', sheet_name='Mean_Level') #read in data\n",
    "philly_dates = pd.read_csv('philly_release_dates.csv')\n",
    "df = df[df['YEAR'].notna()] #drop last col which shows up as NaT in index (not sure why this shows up...)\n",
    "df['YEAR'] = df['YEAR'].astype(int).astype(str) #cast year to string for Period index\n",
    "df['QUARTER'] = df['QUARTER'].astype(int).astype(str) #cast quarter to string for Period index\n",
    "df['Period'] = df[['YEAR', 'QUARTER']].agg('-Q'.join, axis=1) #combine year and quarter data into Period\n",
    "df['Period'] = pd.to_datetime(df['Period']) #set Period to datetime\n",
    "df.set_index('Period', inplace=True) #set Period as df index\n",
    "df = df['1999-10-01':]\n",
    "philly_dates = philly_dates.set_index(df.index)\n",
    "df['observation_dates'] = philly_dates['Period']\n",
    "df = df.set_index(df['observation_dates'])\n",
    "df.index = pd.to_datetime(df.index)\n",
    "GDP_cols_list = ['RGDP1', 'RGDP2', 'RGDP3'] #identify columns we want to retain and lag\n",
    "df = df.filter(GDP_cols_list, axis=1) #retain columns we want\n",
    "df[GDP_cols_list] = df[GDP_cols_list].shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period\n",
    "df['gdp+1_mean'] = df[['RGDP1', 'RGDP2']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast 1evels \n",
    "df['gdp+2_mean'] = df[['RGDP2', 'RGDP3']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast levels \n",
    "mean_GDP_forecasts = ['gdp+1_mean', 'gdp+2_mean'] #identify columns to retain\n",
    "mean_GDP_forecasts = df.filter(mean_GDP_forecasts, axis=1) #filter for wanted columns\n",
    "mean_GDP_forecasts.index.name = 'observation_date'\n",
    "mean_GDP_forecasts.to_csv('mean_GDP_forecasts.csv')\n",
    "\n",
    "FOMC_df = pd.DataFrame(index=FOMC_meets)\n",
    "FOMC_df.index = pd.to_datetime(FOMC_df.index)\n",
    "FOMC_df.index.name = 'observation_date'\n",
    "\n",
    "FOMC_gdp = pd.merge_asof(FOMC_df, mean_GDP_forecasts, on = 'observation_date',direction='backward')\n",
    "FOMC_gdp.set_index('observation_date', inplace=True)\n",
    "# FOMC_gdp['2000-01-01':].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdp-1</th>\n",
       "      <th>gdp-0</th>\n",
       "      <th>gdp+1_mean</th>\n",
       "      <th>gdp+2_mean</th>\n",
       "      <th>price-1</th>\n",
       "      <th>price-0</th>\n",
       "      <th>EPU Std 30 Day MA</th>\n",
       "      <th>SPX Std 30 Day MA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-02-02</th>\n",
       "      <td>1.389743</td>\n",
       "      <td>1.419005</td>\n",
       "      <td>0.741383</td>\n",
       "      <td>0.790307</td>\n",
       "      <td>0.268895</td>\n",
       "      <td>0.507614</td>\n",
       "      <td>-0.900118</td>\n",
       "      <td>1.279875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-21</th>\n",
       "      <td>1.389743</td>\n",
       "      <td>1.688650</td>\n",
       "      <td>1.031194</td>\n",
       "      <td>0.901730</td>\n",
       "      <td>0.268895</td>\n",
       "      <td>0.498037</td>\n",
       "      <td>-0.883935</td>\n",
       "      <td>1.225654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-16</th>\n",
       "      <td>1.772562</td>\n",
       "      <td>1.321206</td>\n",
       "      <td>1.031194</td>\n",
       "      <td>0.901730</td>\n",
       "      <td>0.487339</td>\n",
       "      <td>0.665652</td>\n",
       "      <td>-0.918470</td>\n",
       "      <td>1.299294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-28</th>\n",
       "      <td>1.772562</td>\n",
       "      <td>1.322312</td>\n",
       "      <td>0.802572</td>\n",
       "      <td>0.838087</td>\n",
       "      <td>0.487339</td>\n",
       "      <td>0.665652</td>\n",
       "      <td>-0.736161</td>\n",
       "      <td>1.296398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-22</th>\n",
       "      <td>1.338910</td>\n",
       "      <td>1.272874</td>\n",
       "      <td>0.802572</td>\n",
       "      <td>0.838087</td>\n",
       "      <td>0.751236</td>\n",
       "      <td>0.621645</td>\n",
       "      <td>-0.963599</td>\n",
       "      <td>1.338053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-15</th>\n",
       "      <td>0.521779</td>\n",
       "      <td>0.519729</td>\n",
       "      <td>-9.110431</td>\n",
       "      <td>2.373880</td>\n",
       "      <td>0.451089</td>\n",
       "      <td>0.314167</td>\n",
       "      <td>1.114888</td>\n",
       "      <td>3.606619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>0.521779</td>\n",
       "      <td>0.527469</td>\n",
       "      <td>-9.110431</td>\n",
       "      <td>2.373880</td>\n",
       "      <td>0.451089</td>\n",
       "      <td>0.316829</td>\n",
       "      <td>7.910614</td>\n",
       "      <td>2.947602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-10</th>\n",
       "      <td>0.527469</td>\n",
       "      <td>-1.286382</td>\n",
       "      <td>4.508601</td>\n",
       "      <td>1.348393</td>\n",
       "      <td>0.316829</td>\n",
       "      <td>0.341484</td>\n",
       "      <td>5.015778</td>\n",
       "      <td>3.387269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-29</th>\n",
       "      <td>0.527469</td>\n",
       "      <td>-1.272539</td>\n",
       "      <td>4.508601</td>\n",
       "      <td>1.348393</td>\n",
       "      <td>0.316829</td>\n",
       "      <td>0.348562</td>\n",
       "      <td>4.407042</td>\n",
       "      <td>3.635930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16</th>\n",
       "      <td>-1.272539</td>\n",
       "      <td>-9.093019</td>\n",
       "      <td>1.116797</td>\n",
       "      <td>0.841820</td>\n",
       "      <td>0.348562</td>\n",
       "      <td>-0.504498</td>\n",
       "      <td>2.712051</td>\n",
       "      <td>3.965752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               gdp-1     gdp-0  gdp+1_mean  gdp+2_mean   price-1   price-0  \\\n",
       "2000-02-02  1.389743  1.419005    0.741383    0.790307  0.268895  0.507614   \n",
       "2000-03-21  1.389743  1.688650    1.031194    0.901730  0.268895  0.498037   \n",
       "2000-05-16  1.772562  1.321206    1.031194    0.901730  0.487339  0.665652   \n",
       "2000-06-28  1.772562  1.322312    0.802572    0.838087  0.487339  0.665652   \n",
       "2000-08-22  1.338910  1.272874    0.802572    0.838087  0.751236  0.621645   \n",
       "...              ...       ...         ...         ...       ...       ...   \n",
       "2020-03-15  0.521779  0.519729   -9.110431    2.373880  0.451089  0.314167   \n",
       "2020-04-29  0.521779  0.527469   -9.110431    2.373880  0.451089  0.316829   \n",
       "2020-06-10  0.527469 -1.286382    4.508601    1.348393  0.316829  0.341484   \n",
       "2020-07-29  0.527469 -1.272539    4.508601    1.348393  0.316829  0.348562   \n",
       "2020-09-16 -1.272539 -9.093019    1.116797    0.841820  0.348562 -0.504498   \n",
       "\n",
       "            EPU Std 30 Day MA  SPX Std 30 Day MA  \n",
       "2000-02-02          -0.900118           1.279875  \n",
       "2000-03-21          -0.883935           1.225654  \n",
       "2000-05-16          -0.918470           1.299294  \n",
       "2000-06-28          -0.736161           1.296398  \n",
       "2000-08-22          -0.963599           1.338053  \n",
       "...                       ...                ...  \n",
       "2020-03-15           1.114888           3.606619  \n",
       "2020-04-29           7.910614           2.947602  \n",
       "2020-06-10           5.015778           3.387269  \n",
       "2020-07-29           4.407042           3.635930  \n",
       "2020-09-16           2.712051           3.965752  \n",
       "\n",
       "[176 rows x 8 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_df = vintage_gdp_changes.join(FOMC_gdp)\n",
    "macro_df = macro_df.join(vintage_gdp_price_changes)\n",
    "macro_df = macro_df.join(FOMC_epu)\n",
    "macro_df = macro_df.join(FOMC_spx)\n",
    "macro_df\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Double check this on Monday!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Median GDP Forecast Data from FRB Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://www.philadelphiafed.org/surveys-and-data/rgdp\n",
    "#Note: 'Median Responses' as of 1/10/2021\n",
    "df = pd.read_excel(io='Median_RGDP_Level.xlsx', sheet_name='Median_Level') #read in data\n",
    "df = df[df['YEAR'].notna()] #drop last col which shows up as NaT in index (not sure why this shows up...)\n",
    "df['YEAR'] = df['YEAR'].astype(int).astype(str) #cast year to string for Period index\n",
    "df['QUARTER'] = df['QUARTER'].astype(int).astype(str) #cast quarter to string for Period index\n",
    "df['Period'] = df[['YEAR', 'QUARTER']].agg('-Q'.join, axis=1) #combine year and quarter data into Period\n",
    "df['Period'] = pd.to_datetime(df['Period']) #set Period to datetime\n",
    "df.set_index('Period', inplace=True) #set Period as df index\n",
    "df.index = df.index.to_period(\"Q\") #format index\n",
    "GDP_cols_list = ['RGDP1', 'RGDP2', 'RGDP3'] #identify columns we want to retain and lag\n",
    "df = df.filter(GDP_cols_list, axis=1) #retain columns we want\n",
    "df[GDP_cols_list] = df[GDP_cols_list].shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period) \n",
    "df = df[df['RGDP1'].notna()] #remove rows where RGDP1 has NaN\n",
    "df['1Q Ahead Median GDP Forecast'] = df[['RGDP1', 'RGDP2']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast 1\n",
    "df['2Q Ahead Median GDP Forecast'] = df[['RGDP2', 'RGDP3']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast 1\n",
    "median_GDP_forecasts = ['1Q Ahead Median GDP Forecast', '2Q Ahead Median GDP Forecast'] #identify columns to retain\n",
    "median_GDP_forecasts = df.filter(median_GDP_forecasts, axis=1) #filter for wanted columns\n",
    "# median_GDP_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Mean GDP Price Index Forecast Data from FRB Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://www.philadelphiafed.org/surveys-and-data/pgdp\n",
    "#Note: 'Mean Responses' as of 1/12/2021\n",
    "df = pd.read_excel(io='Mean_PGDP_Level.xlsx', sheet_name='Mean_Level') #read in data\n",
    "df = df[df['YEAR'].notna()] #drop last col which shows up as NaT in index (not sure why this shows up...)\n",
    "df['YEAR'] = df['YEAR'].astype(int).astype(str) #cast year to string for Period index\n",
    "df['QUARTER'] = df['QUARTER'].astype(int).astype(str) #cast quarter to string for Period index\n",
    "df['Period'] = df[['YEAR', 'QUARTER']].agg('-Q'.join, axis=1) #combine year and quarter data into Period\n",
    "df['Period'] = pd.to_datetime(df['Period']) #set Period to datetime\n",
    "df.set_index('Period', inplace=True) #set Period as df index\n",
    "df.index = df.index.to_period(\"Q\") #format index\n",
    "PGDP_cols_list = ['PGDP1', 'PGDP2', 'PGDP3'] #identify columns we want to retain and lag\n",
    "df = df.filter(PGDP_cols_list, axis=1) #retain columns we want\n",
    "df[PGDP_cols_list] = df[PGDP_cols_list].shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period\n",
    "df = df[df['PGDP1'].notna()] #remove rows where RGDP1 has NaN\n",
    "df['1Q Ahead Mean GDP Price Forecast'] = df[['PGDP1', 'PGDP2']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast 1evels \n",
    "df['2Q Ahead Mean GDP Price Forecast'] = df[['PGDP2', 'PGDP3']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast levels \n",
    "mean_PGDP_forecasts = ['1Q Ahead Mean GDP Price Forecast', '2Q Ahead Mean GDP Price Forecast'] #identify columns to retain\n",
    "mean_PGDP_forecasts = df.filter(mean_PGDP_forecasts, axis=1) #filter for wanted columns\n",
    "# mean_PGDP_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and Format Median GDP Price Index Forecast Data from FRB Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://www.philadelphiafed.org/surveys-and-data/pgdp\n",
    "#Note: 'Median Responses' as of 1/12/2021\n",
    "df = pd.read_excel(io='Median_PGDP_Level.xlsx', sheet_name='Median_Level') #read in data\n",
    "#print(df)\n",
    "df = df[df['YEAR'].notna()] #drop last col which shows up as NaT in index (not sure why this shows up...)\n",
    "df['YEAR'] = df['YEAR'].astype(int).astype(str) #cast year to string for Period index\n",
    "df['QUARTER'] = df['QUARTER'].astype(int).astype(str) #cast quarter to string for Period index\n",
    "df['Period'] = df[['YEAR', 'QUARTER']].agg('-Q'.join, axis=1) #combine year and quarter data into Period\n",
    "df['Period'] = pd.to_datetime(df['Period']) #set Period to datetime\n",
    "df.set_index('Period', inplace=True) #set Period as df index\n",
    "df.index = df.index.to_period(\"Q\") #format index\n",
    "PGDP_cols_list = ['PGDP1', 'PGDP2', 'PGDP3'] #identify columns we want to retain and lag\n",
    "df = df.filter(PGDP_cols_list, axis=1) #retain columns we want\n",
    "df[PGDP_cols_list] = df[PGDP_cols_list].shift(-1) #lag values to correct index (as Philly Fed index is to the forecast, not GDP period\n",
    "df = df[df['PGDP1'].notna()] #remove rows where RGDP1 has NaN\n",
    "df['1Q Ahead Median GDP Price Forecast'] = df[['PGDP1', 'PGDP2']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast 1evels \n",
    "df['2Q Ahead Median GDP Price Forecast'] = df[['PGDP2', 'PGDP3']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1) #calculate pct change from actual to forecast levels \n",
    "median_PGDP_forecasts = ['1Q Ahead Median GDP Price Forecast', '2Q Ahead Median GDP Price Forecast'] #identify columns to retain\n",
    "median_PGDP_forecasts = df.filter(median_PGDP_forecasts, axis=1) #filter for wanted columns\n",
    "# median_PGDP_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine GDP Data from ALFRED & Philly Fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_data = GDP_actuals.join(mean_GDP_forecasts) #left join the GDP_acuals and mean_GDP_forecasts\n",
    "GDP_data = GDP_data.join(median_GDP_forecasts) #left join the GDP_acuals and median_GDP_forecasts\n",
    "GDP_data = GDP_data.loc['2000Q1':] #remove rows outside of our period\n",
    "GDP_data.index = GDP_data.index.strftime('%m/%d/%Y') #set index format to m/d/yyyy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine PCE Data from ALFRED & Philly Fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PCE_forecasts = mean_PCE_forecasts.join(median_PCE_forecasts)\n",
    "PCE_data = PCE_actuals.join(PCE_forecasts)\n",
    "# # Test for data continuity\n",
    "# print('Corr Median & FRED Actual', PCE_data['Curr PCE Pct Chg'].corr(PCE_data['COREPCE - Median'])) #check for data continuity across the FRED actual and Philly Fed forcast data\n",
    "# print('Corr Median & FRED Actual', PCE_data['Curr PCE Pct Chg'].corr(PCE_data['COREPCE - Mean'])) #check for data continuity across the FRED actual and Philly Fed forcast data\n",
    "PCE_data_to_drop = ['COREPCE - Median','COREPCE - Mean']\n",
    "PCE_data = PCE_data.drop(PCE_data_to_drop, axis=1)\n",
    "PCE_data.index = PCE_data.index.strftime('%m/%d/%Y') #set index format to m/d/yyyy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine PGDP Data from ALFRED & Philly Fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PGDP_forecasts = mean_PGDP_forecasts.join(median_PGDP_forecasts)\n",
    "PGDP_data = PGDP_actuals.join(PGDP_forecasts)\n",
    "PGDP_data = PGDP_data.loc['2000Q1':] #remove rows outside of our period\n",
    "PGDP_data.index = PGDP_data.index.strftime('%m/%d/%Y') #set index format to m/d/yyyy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Datasets for Shock Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Miles, this one is for you. Call the ball. :)\n",
    "'''\n",
    "\n",
    "macro_data = GDP_data.join(PGDP_data)\n",
    "# macro_data\n",
    "# macro_data.to_csv('macro_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
